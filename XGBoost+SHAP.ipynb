{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaf2552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import xgboost as xgb\n",
    "\n",
    "# 读取数据\n",
    "data_features = pd.read_csv(r'')\n",
    "data_labels = pd.read_csv(r'')\n",
    "\n",
    "# 检查两个表格的ID名称是否一致\n",
    "if not all(data_features['ID'] == data_labels['ID']):\n",
    "    mismatched_ids = data_features['ID'][data_features['ID'] != data_labels['ID']]\n",
    "    print(\"IDs in the two dataframes do not match. Mismatched IDs:\")\n",
    "    print(mismatched_ids)\n",
    "    raise ValueError(\"IDs do not match.\")\n",
    "else:\n",
    "    print(\"ID配对一致\")\n",
    "\n",
    "# 检查标签数据分布\n",
    "print(\"Original label data distribution:\")\n",
    "print(data_labels['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525ffe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并数据\n",
    "merged_data = pd.merge(data_features, data_labels, on='ID')\n",
    "\n",
    "# 提取特征和标签\n",
    "X = merged_data.drop(columns=['ID', 'label', 'group'])\n",
    "y = merged_data['label']\n",
    "\n",
    "# 确保标签的编码与原始标签一致\n",
    "label_mapping = {0: 0, 1: 1, 2: 2}\n",
    "y = y.map(label_mapping)\n",
    "\n",
    "# 根据group列划分训练集、验证集和测试集\n",
    "train_indices = merged_data[merged_data['group'] == 'train'].index\n",
    "val_indices = merged_data[merged_data['group'] == 'val'].index\n",
    "test_indices = merged_data[merged_data['group'] == 'test'].index\n",
    "\n",
    "X_train, X_val, X_test = X.loc[train_indices], X.loc[val_indices], X.loc[test_indices]\n",
    "y_train, y_val, y_test = y.loc[train_indices], y.loc[val_indices], y.loc[test_indices]\n",
    "\n",
    "# 打印训练集、验证集和测试集的标签分布\n",
    "print(\"Training data distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"Validation data distribution:\")\n",
    "print(y_val.value_counts())\n",
    "print(\"Test data distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用SMOTE和RandomUnderSampler来处理类别不平衡\n",
    "smote = SMOTE(random_state=42)\n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# 重新采样\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = under_sampler.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "# 打印重新采样后的数据分布\n",
    "print(\"\\nResampled training data:\")\n",
    "print(pd.Series(y_resampled).value_counts())\n",
    "print(\"Number of samples:\", len(y_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130f7dfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义XGBoost模型和参数网格\n",
    "xgb_params = {\n",
    "    'xgb__n_estimators': [100, 200, 300],\n",
    "    'xgb__max_depth': [3, 4, 5, 6],\n",
    "    'xgb__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'xgb__subsample': [0.6, 0.8, 1.0],\n",
    "    'xgb__colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# 创建XGBoost模型实例\n",
    "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# 使用SMOTE和RandomUnderSampler来处理类别不平衡\n",
    "resampling_pipeline = Pipeline(steps=[('over', smote), ('under', under_sampler), ('xgb', xgb_clf)])\n",
    "\n",
    "# 创建超参数搜索实例\n",
    "xgb_grid = GridSearchCV(resampling_pipeline, xgb_params, cv=2, scoring='roc_auc', verbose=1, n_jobs=-1)\n",
    "\n",
    "# 训练模型\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best parameters for XGBoost with SMOTE and RandomUnderSampler:\", xgb_grid.best_params_)\n",
    "\n",
    "# 使用最佳参数重新训练模型\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "\n",
    "# 预测训练集、验证集和测试集\n",
    "y_train_pred_xgb = xgb_best.predict(X_train)\n",
    "y_train_score_xgb = xgb_best.predict_proba(X_train)\n",
    "y_val_pred_xgb = xgb_best.predict(X_val)\n",
    "y_val_score_xgb = xgb_best.predict_proba(X_val)\n",
    "y_test_pred_xgb = xgb_best.predict(X_test)\n",
    "y_test_score_xgb = xgb_best.predict_proba(X_test)\n",
    "\n",
    "#Best parameters for XGBoost with SMOTE and RandomUnderSampler: \n",
    "#{'xgb__colsample_bytree': 0.6, 'xgb__learning_rate': 0.01, 'xgb__max_depth': 3, 'xgb__n_estimators': 100, 'xgb__subsample': 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0983cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存每个样本的预测概率\n",
    "train_ids = data_features.loc[train_indices, 'ID'].reset_index(drop=True)\n",
    "val_ids = data_features.loc[val_indices, 'ID'].reset_index(drop=True)\n",
    "test_ids = data_features.loc[test_indices, 'ID'].reset_index(drop=True)\n",
    "\n",
    "pd.concat([train_ids, pd.DataFrame(y_train_score_xgb, columns=['Class_0_Prob', 'Class_1_Prob', 'Class_2_Prob'])], axis=1).to_csv('table\\XGBoost_Training_Predicted_Probabilities.csv', index=False)\n",
    "pd.concat([val_ids, pd.DataFrame(y_val_score_xgb, columns=['Class_0_Prob', 'Class_1_Prob', 'Class_2_Prob'])], axis=1).to_csv('table\\XGBoost_Validation_Predicted_Probabilities.csv', index=False)\n",
    "pd.concat([test_ids, pd.DataFrame(y_test_score_xgb, columns=['Class_0_Prob', 'Class_1_Prob', 'Class_2_Prob'])], axis=1).to_csv('table\\XGBoost_Test_Predicted_Probabilities.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e00586d",
   "metadata": {},
   "source": [
    "# SHAP图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a66d19",
   "metadata": {},
   "source": [
    "全局SHAP图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e3c1c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 假设 SHAP 值计算如下\n",
    "explainer = shap.Explainer(xgb_best.named_steps['xgb'])\n",
    "shap_values = explainer(X_train)\n",
    "\n",
    "# 选择每个类别的 SHAP 值\n",
    "shap_values_class_0 = shap_values[:, :, 0]\n",
    "shap_values_class_1 = shap_values[:, :, 1]\n",
    "shap_values_class_2 = shap_values[:, :, 2]\n",
    "\n",
    "def save_shap_summary_plot(shap_values, class_name, file_path):\n",
    "    # 生成一个新的图形\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # 绘制SHAP汇总图\n",
    "    shap.summary_plot(shap_values, X_train, show=False, plot_type='dot', cmap='viridis')\n",
    "    #cmap=\"?\"配色viridis Spectral coolwar mRdYlGn RdYlBu RdBu RdGy PuOr BrBG PRGn PiYG\n",
    "#     \"viridis\"：从黄色到蓝绿色。\"Spectral\"：从红色到蓝色，适用于有正负影响的特征。\"coolwarm\"：从冷到暖的颜色图。\n",
    "#     \"RdYlGn\"：从红到绿的颜色图。\"RdYlBu\"：从红到蓝的颜色图。\"RdBu\"：红蓝双色图。\"RdGy\"：红灰双色图。\n",
    "#     \"PuOr\"：从紫色到橙色的颜色图。\"BrBG\"：从棕色到蓝绿色的颜色图。\"PRGn\"：从紫色到绿色的颜色图。\n",
    "#     \"PiYG\"：从粉红色到绿色的颜色图\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # 获取SHAP值的范围\n",
    "    shap_values_np = shap_values.values  # 将SHAP值转为numpy数组\n",
    "    min_shap, max_shap = np.min(shap_values_np), np.max(shap_values_np)\n",
    "    \n",
    "    # 扩展SHAP值的范围以减少点的密集\n",
    "    extended_min_shap = min_shap - (max_shap - min_shap) * 0.01  # 扩展范围的10%\n",
    "    extended_max_shap = max_shap + (max_shap - min_shap) * 0.01\n",
    "    \n",
    "    # 设置SHAP值的范围\n",
    "    ax.set_xlim(extended_min_shap, extended_max_shap)\n",
    "    \n",
    "    # 调整特征名称和SHAP值的字体大小\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(8)  # 调整特征名称的字体大小\n",
    "    \n",
    "    # 设置标题的字体大小\n",
    "    plt.title(class_name, fontsize=12)\n",
    "    \n",
    "    # 获取当前图例\n",
    "    legend = plt.gca().get_legend()\n",
    "    \n",
    "    if legend:\n",
    "        # 设置图例字体大小\n",
    "        for text in legend.get_texts():\n",
    "            text.set_fontsize(10)  # 调整图例字体大小\n",
    "    \n",
    "    # 自动调整子图参数\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 保存SHAP图\n",
    "    plt.savefig(file_path, format='png', dpi=300, bbox_inches='tight')  # 自动调整边界\n",
    "    \n",
    "\n",
    "# 保存SHAP图\n",
    "save_shap_summary_plot(shap_values_class_0, 'HER2-zero', r'')\n",
    "save_shap_summary_plot(shap_values_class_1, 'HER2-low', r'')\n",
    "save_shap_summary_plot(shap_values_class_2, 'HER2-positive', r'')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a013f",
   "metadata": {},
   "source": [
    "分habitat的SHAP图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129a828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 假设 SHAP 值计算如下\n",
    "explainer = shap.Explainer(xgb_best.named_steps['xgb'])\n",
    "shap_values = explainer(X_train)\n",
    "\n",
    "# 选择每个类别的 SHAP 值\n",
    "shap_values_class_0 = shap_values[:, :, 0]\n",
    "shap_values_class_1 = shap_values[:, :, 1]\n",
    "shap_values_class_2 = shap_values[:, :, 2]\n",
    "\n",
    "# 获取特征列名\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# 定义保存 SHAP summary 图的函数\n",
    "def save_shap_summary_plot(features, shap_values, X_train, class_name, suffix):\n",
    "    # 筛选出特定后缀的特征及其对应的SHAP值\n",
    "    feature_indices = [i for i, feat in enumerate(features) if feat.endswith(suffix)]\n",
    "    if not feature_indices:\n",
    "        print(f\"No features with suffix {suffix} for class {class_name}\")\n",
    "        return\n",
    "    \n",
    "    X_train_selected = X_train.iloc[:, feature_indices]\n",
    "    shap_values_selected = shap_values.values[:, feature_indices]\n",
    "    \n",
    "    # 生成一个新的图形\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # 绘制SHAP汇总图\n",
    "    shap.summary_plot(shap_values_selected, X_train_selected, show=False, plot_type='dot', cmap='viridis')\n",
    "    ax = plt.gca()\n",
    "    #     #cmap=\"?\"配色viridis Spectral coolwar mRdYlGn RdYlBu RdBu RdGy PuOr BrBG PRGn PiYG\n",
    "# #     \"viridis\"：从黄色到蓝绿色。\"Spectral\"：从红色到蓝色，适用于有正负影响的特征。\"coolwarm\"：从冷到暖的颜色图。\n",
    "# #     \"RdYlGn\"：从红到绿的颜色图。\"RdYlBu\"：从红到蓝的颜色图。\"RdBu\"：红蓝双色图。\"RdGy\"：红灰双色图。\n",
    "# #     \"PuOr\"：从紫色到橙色的颜色图。\"BrBG\"：从棕色到蓝绿色的颜色图。\"PRGn\"：从紫色到绿色的颜色图。\n",
    "# #     \"PiYG\"：从粉红色到绿色的颜色图\n",
    "    # 获取SHAP值的范围\n",
    "    min_shap, max_shap = np.min(shap_values_selected), np.max(shap_values_selected)\n",
    "    \n",
    "    # 扩展SHAP值的范围以减少点的密集\n",
    "    extended_min_shap = min_shap - (max_shap - min_shap) * 0.01  # 扩展范围的1%\n",
    "    extended_max_shap = max_shap + (max_shap - min_shap) * 0.01\n",
    "    \n",
    "    # 设置SHAP值的范围\n",
    "    ax.set_xlim(extended_min_shap, extended_max_shap)\n",
    "    \n",
    "    # 调整特征名称和SHAP值的字体大小\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(8)  # 调整特征名称的字体大小\n",
    "    \n",
    "    # 设置标题的字体大小\n",
    "    plt.title(f'{class_name} - {suffix}', fontsize=12)\n",
    "    \n",
    "    # 获取当前图例\n",
    "    legend = plt.gca().get_legend()\n",
    "    \n",
    "    if legend:\n",
    "        # 设置图例字体大小\n",
    "        for text in legend.get_texts():\n",
    "            text.set_fontsize(10)  # 调整图例字体大小\n",
    "    \n",
    "    # 自动调整子图参数\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 保存SHAP图\n",
    "    file_path = rf'shap_summary_plot_{class_name}_{suffix}.png'\n",
    "    plt.savefig(file_path, format='png', dpi=300, bbox_inches='tight')  # 自动调整边界\n",
    "    \n",
    "\n",
    "# 保存SHAP图\n",
    "suffixes = ['_h1', '_h2', '_h3', '_h4']\n",
    "for class_name, shap_values_class in zip(['HER2-zero', 'HER2-low', 'HER2-positive'], [shap_values_class_0, shap_values_class_1, shap_values_class_2]):\n",
    "    for suffix in suffixes:\n",
    "        save_shap_summary_plot(feature_names, shap_values_class, X_train, class_name, suffix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094a0509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 选择一个观测值（这里选择训练集中的第一个实例）\n",
    "single_observation = X_train.iloc[[312]] # 需要是DataFrame格式\n",
    "\n",
    "# 创建SHAP解释器对象\n",
    "explainer = shap.Explainer(xgb_best.named_steps['xgb'], X_train)\n",
    "\n",
    "# 计算所选观测值的SHAP值\n",
    "shap_values = explainer(single_observation)\n",
    "\n",
    "# 选择每个类别的SHAP值\n",
    "shap_values_class_0 = shap_values[:, :, 0]\n",
    "shap_values_class_1 = shap_values[:, :, 1]\n",
    "shap_values_class_2 = shap_values[:, :, 2]\n",
    "\n",
    "# 绘制所选观测值的SHAP值瀑布图并保存为PNG格式\n",
    "def save_and_show_shap_plot(shap_values, class_label, base_path):\n",
    "    # 创建SHAP瀑布图，获取Axes对象\n",
    "    shap_plot = shap.plots.waterfall(shap_values[0], show=False)\n",
    "    \n",
    "    # 获取Figure对象\n",
    "    fig = shap_plot.figure\n",
    "    \n",
    "    # 保存图形为PNG格式\n",
    "    fig.savefig(f'{base_path}/shap_waterfall_class_{class_label}.png', bbox_inches='tight', format='png', dpi=300)\n",
    "    \n",
    "    # 显示图形\n",
    "    plt.show(fig)\n",
    "   # 关闭图形以释放内存\n",
    "    plt.close(fig)\n",
    "\n",
    "# 设置保存路径\n",
    "base_path = r''\n",
    "\n",
    "# 保存并显示SHAP瀑布图\n",
    "save_and_show_shap_plot(shap_values_class_0, 0, base_path)\n",
    "save_and_show_shap_plot(shap_values_class_1, 1, base_path)\n",
    "save_and_show_shap_plot(shap_values_class_2, 2, base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20baeb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估模型\n",
    "def evaluate_model(y_true, y_pred, y_score, label_mapping):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, target_names=[str(i) for i in label_mapping.keys()], output_dict=True)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    def calculate_metrics(conf_matrix):\n",
    "        sensitivity = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "        precision = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)\n",
    "        specificity = []\n",
    "        for i in range(len(conf_matrix)):\n",
    "            tn = np.sum(np.delete(np.delete(conf_matrix, i, axis=0), i, axis=1))\n",
    "            fp = np.sum(np.delete(conf_matrix, i, axis=0)[:, i])\n",
    "            specificity.append(tn / (tn + fp))\n",
    "        f1_scores = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "        return sensitivity, specificity, precision, f1_scores\n",
    "\n",
    "    sensitivity, specificity, precision, f1_scores = calculate_metrics(conf_matrix)\n",
    "\n",
    "    y_true_binarized = label_binarize(y_true, classes=[0, 1, 2])\n",
    "    n_classes = y_true_binarized.shape[1]\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    return accuracy, report, conf_matrix, sensitivity, specificity, precision, f1_scores, roc_auc, fpr, tpr\n",
    "\n",
    "# 评估XGBoost模型\n",
    "train_results_xgb = evaluate_model(y_train, y_train_pred_xgb, y_train_score_xgb, label_mapping)\n",
    "val_results_xgb = evaluate_model(y_val, y_val_pred_xgb, y_val_score_xgb, label_mapping)\n",
    "test_results_xgb = evaluate_model(y_test, y_test_pred_xgb, y_test_score_xgb, label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176010bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 打印评估结果并生成表格\n",
    "def print_and_save_results(results, title):\n",
    "    accuracy, report, conf_matrix, sensitivity, specificity, precision, f1_scores, roc_auc, fpr, tpr = results\n",
    "    num_classes = conf_matrix.shape[1]\n",
    "    print(f\"{title} Results\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    # 分类报告\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    print(\"Classification Report:\")\n",
    "    print(report_df)\n",
    "    \n",
    "    # 混淆矩阵\n",
    "    conf_matrix_df = pd.DataFrame(conf_matrix, index=label_mapping.keys(), columns=label_mapping.keys())\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_df)\n",
    "    \n",
    "    # 其他评估指标\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Sensitivity\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"Precision\": precision,\n",
    "        \"F1 Score\": f1_scores\n",
    "    }, index=label_mapping.keys())\n",
    "    print(\"Metrics:\")\n",
    "    print(metrics_df)\n",
    "    \n",
    "    # 保存表格\n",
    "    report_df.to_csv(f\"table\\{title}_classification_report.csv\")\n",
    "    conf_matrix_df.to_csv(f\"table\\{title}_confusion_matrix.csv\")\n",
    "    metrics_df.to_csv(f\"table\\{title}_metrics.csv\")\n",
    "\n",
    "print_and_save_results(train_results_xgb, \"XGBoost_Training\")\n",
    "print_and_save_results(val_results_xgb, \"XGBoost_Validation\")\n",
    "print_and_save_results(test_results_xgb, \"XGBoost_Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af572a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_roc_auc_with_ci(y_true, y_score, n_bootstraps=1000, random_state=42):\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "    bootstrapped_aucs = {i: [] for i in range(y_score.shape[1])}\n",
    "    \n",
    "    for i in range(y_score.shape[1]):\n",
    "        # 计算 ROC 曲线和 AUC\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true, y_score[:, i], pos_label=i)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "        rng = np.random.RandomState(random_state)\n",
    "        for _ in range(n_bootstraps):\n",
    "            # 使用引导法计算 AUC\n",
    "            indices = rng.randint(0, len(y_true), len(y_true))\n",
    "            if len(np.unique(y_true[indices])) < 2:\n",
    "                continue\n",
    "            fpr_boot, tpr_boot, _ = roc_curve(y_true[indices], y_score[indices, i], pos_label=i)\n",
    "            roc_auc_boot = auc(fpr_boot, tpr_boot)\n",
    "            bootstrapped_aucs[i].append(roc_auc_boot)\n",
    "    \n",
    "    auc_ci = {}\n",
    "    for i in range(y_score.shape[1]):\n",
    "        sorted_aucs = np.array(bootstrapped_aucs[i])\n",
    "        sorted_aucs.sort()\n",
    "        confidence_lower = np.percentile(sorted_aucs, 2.5)\n",
    "        confidence_upper = np.percentile(sorted_aucs, 97.5)\n",
    "        auc_ci[i] = (confidence_lower, confidence_upper)\n",
    "    \n",
    "    return fpr, tpr, roc_auc, auc_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c364ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, roc_auc, auc_ci, title, class_labels):\n",
    "    plt.figure()\n",
    "    colors = ['aqua', 'darkorange', 'cornflowerblue']\n",
    "    for i, color in enumerate(colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label=f'{class_labels[i]} (AUC = {roc_auc[i]:0.3f}[{auc_ci[i][0]:0.3f}, {auc_ci[i][1]:0.3f}])')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f'figures\\{title.replace(\" \", \"_\")}.tif', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48608bea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compute_and_plot_roc_curve(y_true, y_score, n_classes, title):\n",
    "    # 确保 y_true 是一维数组\n",
    "    y_true = np.asarray(y_true).ravel()\n",
    "    # 确保 y_score 是二维数组\n",
    "    y_score = np.asarray(y_score)\n",
    "    \n",
    "    fpr, tpr, roc_auc, auc_ci = calculate_roc_auc_with_ci(y_true, y_score, n_bootstraps=1000)\n",
    "    # 类别标签\n",
    "    class_labels = ['Her2-zero', 'Her2-low', 'Her2-positive']\n",
    "    plot_roc_curve(fpr, tpr, roc_auc, auc_ci, title, class_labels)\n",
    "\n",
    "# 示例：使用训练集、验证集和测试集的预测结果绘制 ROC 曲线\n",
    "compute_and_plot_roc_curve(y_train, y_train_score_xgb, n_classes=3, title='Training ROC Curve')\n",
    "compute_and_plot_roc_curve(y_val, y_val_score_xgb, n_classes=3, title='Val ROC Curve')\n",
    "compute_and_plot_roc_curve(y_test, y_test_score_xgb, n_classes=3, title='Test ROC Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390430b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405c9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
